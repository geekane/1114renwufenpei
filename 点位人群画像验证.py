# --- START OF FILE V11.py ---

import tkinter as tk
from tkinter import scrolledtext, ttk
import threading
import requests
import json
import time
from datetime import datetime
import numpy as np
import csv
import os
import math

# --- ã€V11 é…ç½®ã€‘ ---
API_KEY = "cfed97bf5c90224abbbb2ede4c008d0b" # è¯·æ›¿æ¢ä¸ºæ‚¨çš„é«˜å¾·API Key
GEOCODE_URL = "https://restapi.amap.com/v3/geocode/geo"
AROUND_SEARCH_URL = "https://restapi.amap.com/v5/place/around"
MAX_RETRY_COUNT = 3
RETRY_DELAY = 1
API_REQUEST_DELAY = 0.1
PAGE_SIZE = 25
MAX_PAGE_NUM = 40

# --- POIæ¨¡å‹é…ç½® V10 (ä¸ä¸Šä¸€ç‰ˆç›¸åŒ) ---
MODEL_POI_CONFIG = {
    "positive": {
        "å•†åœºè´­ç‰©ä¸­å¿ƒ": {"types": "060100|060101", "weight": 2.5, "category": "æ ¸å¿ƒå®¢ç¾¤", "desc": "é«˜æµé‡å•†åœˆçš„æ ¸å¿ƒæ ‡å¿—ï¼Œå®¢æµä¸Šé™é«˜"},
        "å¤§ä¸­ä¸“é™¢æ ¡": {"types": "141200", "weight": 2.2, "category": "æ ¸å¿ƒå®¢ç¾¤", "desc": "ç¨³å®šä¸”åºå¤§çš„å¹´è½»å­¦ç”Ÿå®¢æº"},
        "å†™å­—æ¥¼": {"types": "120100", "weight": 1.8, "category": "æ ¸å¿ƒå®¢ç¾¤", "saturation": 20, "desc": "ç™½é¢†å®¢ç¾¤ï¼Œå…·å¤‡æ¶ˆè´¹èƒ½åŠ›"},
        "ä½å®…å°åŒº": {"types": "120300", "weight": 1.5, "category": "æ ¸å¿ƒå®¢ç¾¤", "saturation": 25, "desc": "å‘¨è¾¹å±…æ°‘åŒºï¼Œæä¾›åŸºç¡€å®¢æµ"},
        "é’å¹´å…¬å¯“": {"keywords": "é’å¹´å…¬å¯“|ç™½é¢†å…¬å¯“|äººæ‰å…¬å¯“", "weight": 2.0, "category": "ååŒä¸šæ€", "saturation": 15, "desc": "æç²¾å‡†çš„å¹´è½»ã€æ´»è·ƒå®¢ç¾¤èšé›†åœ°"},
        "å¤œå¸‚ç¾é£Ÿè¡—": {"keywords": "å¤œå¸‚|ç¾é£Ÿè¡—", "weight": 1.8, "category": "ååŒä¸šæ€", "saturation": 5, "desc": "å¤œé—´ç»æµå’Œå¹´è½»ç¤¾äº¤çš„æ ¸å¿ƒåœºæ‰€"},
        "ç”µå½±é™¢": {"types": "080601", "weight": 1.6, "category": "ååŒä¸šæ€", "saturation": 5, "desc": "äº’è¡¥çš„å¨±ä¹ä¸šæ€ï¼Œèƒ½å…±äº«å®¢æµ"},
        "çƒ­é—¨å¿«é¤å¥¶èŒ¶": {"keywords": "èœœé›ªå†°åŸ|åè±å£«|ç‘å¹¸|æ˜Ÿå·´å…‹", "weight": 1.5, "category": "ååŒä¸šæ€", "saturation": 10, "desc": "å¹´è½»æ¶ˆè´¹é£å‘æ ‡ï¼ŒéªŒè¯åŒºåŸŸå®¢ç¾¤æ´»è·ƒåº¦"},
        "KTV": {"types": "080301", "weight": 1.2, "category": "ååŒä¸šæ€", "saturation": 10},
        "é…’å§": {"types": "080500", "weight": 1.2, "category": "ååŒä¸šæ€", "saturation": 15},
        "å¿«é¤å°åƒ": {"types": "050300|050100", "weight": 1.0, "category": "ååŒä¸šæ€", "saturation": 25},
        "å®¾é¦†é…’åº—": {"types": "100100", "weight": 0.8, "category": "ååŒä¸šæ€", "saturation": 20},
        "åœ°é“ç«™": {"types": "150500", "weight": 2.0, "category": "åŸºç¡€è®¾æ–½", "desc": "äº¤é€šæ¢çº½ï¼Œæå¤§æå‡è¾å°„èŒƒå›´å’Œå®¢æµå¯¼å…¥"},
        "å…¬äº¤ç«™": {"types": "150700", "weight": 0.5, "category": "åŸºç¡€è®¾æ–½", "saturation": 20},
    },
    "negative": {
        "ç½‘å§": {"types": "080601", "weight": 4.0, "category": "ç›´æ¥ç«äº‰"},
        "ç”µç«é…’åº—": {"types": "100108", "weight": 3.5, "category": "ç›´æ¥ç«äº‰"},
        "ä¸­å°å­¦æ ¡": {"types": "141202|141203", "weight": 10.0, "category": "æ”¿ç­–é£é™©", "desc": "æ³•è§„çº¢çº¿ï¼Œ200ç±³å†…ç¦æ­¢å¼€è®¾"},
        "å·¥ä¸šå›­åŒº": {"types": "170205", "weight": 1.5, "category": "é£é™©å®¢ç¾¤", "desc": "äººç¾¤ç”»åƒè€åŒ–ï¼Œæ¶ˆè´¹æ„æ„¿å’Œèƒ½åŠ›å¯èƒ½ä¸åŒ¹é…"},
    }
}

# ... æ•°æ®å¤‡ä»½åŠåç«¯æ ¸å¿ƒè¯·æ±‚å‡½æ•° (ä¸V10å®Œå…¨ç›¸åŒ) ...
def backup_raw_data_to_csv(backup_writer, request_type, params, response_data, poi_name=None):
    if not response_data: return
    backup_writer.writerow({
        "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        "request_type": request_type,
        "poi_name": poi_name,
        "request_params": json.dumps(params, ensure_ascii=False),
        "response_status": response_data.get('status', 'N/A'),
        "response_infocode": response_data.get('infocode', 'N/A'),
        "response_count": response_data.get('count', 'N/A'),
        "raw_json_response": json.dumps(response_data, ensure_ascii=False)
    })

class AnalysisCore:
    def __init__(self, logger_func, update_insight_func, backup_writer):
        self.log = logger_func
        self.update_insight = update_insight_func
        self.backup_writer = backup_writer

    def get_coordinates(self, address: str) -> tuple | None:
        self.log(f"ğŸ“Œ æ­£åœ¨æŸ¥è¯¢åœ°å€: '{address}' ...")
        params = {'key': API_KEY, 'address': address}
        for _ in range(MAX_RETRY_COUNT):
            try:
                time.sleep(API_REQUEST_DELAY)
                response = requests.get(GEOCODE_URL, params=params, timeout=10)
                response.raise_for_status()
                data = response.json()
                backup_raw_data_to_csv(self.backup_writer, "geocode", params, data)
                if data.get('status') == '1' and int(data.get('count', 0)) > 0:
                    lon, lat = map(float, data['geocodes'][0]['location'].split(','))
                    self.log(f"âœ… æŸ¥è¯¢æˆåŠŸ: {lon:.6f}, {lat:.6f}\n")
                    return lon, lat
            except requests.exceptions.RequestException: time.sleep(RETRY_DELAY)
        self.log(f"âŒ åœ°ç†ç¼–ç å¤±è´¥: {address}"); return None

    def search_nearby_poi_details_full(self, location_coords: tuple, radius: int, poi_types: str = None, keywords: str = None, poi_name: str = "Unknown") -> list:
        all_pois, page_num = [], 1
        while page_num <= MAX_PAGE_NUM:
            params = {'key': API_KEY, 'location': f"{location_coords[0]},{location_coords[1]}", 'radius': radius, 'page_size': PAGE_SIZE, 'page_num': page_num, 'show_fields': 'business'}
            if keywords: params['keywords'] = keywords
            elif poi_types: params['types'] = poi_types
            else: break
            try:
                time.sleep(API_REQUEST_DELAY)
                response = requests.get(AROUND_SEARCH_URL, params=params, timeout=10)
                response.raise_for_status()
                data = response.json()
                backup_raw_data_to_csv(self.backup_writer, "around_search", params, data, poi_name=poi_name)
                if data.get('status') == '1':
                    pois_on_page = data.get('pois', [])
                    if not pois_on_page: break
                    all_pois.extend(pois_on_page)
                    if len(pois_on_page) < PAGE_SIZE: break
                    page_num += 1
                else: break
            except (requests.exceptions.RequestException, json.JSONDecodeError): break
        return all_pois

    def clean_poi_list(self, poi_list: list, expected_types: str) -> list:
        if not expected_types: return poi_list
        cleaned_list, expected_type_set = [], set(expected_types.split('|'))
        for poi in poi_list:
            poi_typecodes = set(poi.get('typecode', '').split(';'))
            if not expected_type_set.isdisjoint(poi_typecodes):
                cleaned_list.append(poi)
        if len(poi_list) != len(cleaned_list):
            self.log(f"    -> æ•°æ®æ¸…æ´—: {len(poi_list)}æ¡ -> {len(cleaned_list)}æ¡æœ‰æ•ˆæ•°æ®ã€‚")
        return cleaned_list

    def analyze_poi_details(self, poi_list: list) -> dict:
        ratings, costs = [], []
        for poi in poi_list:
            business = poi.get('business', {})
            try:
                if business.get('rating'): ratings.append(float(business['rating']))
                if business.get('cost') and float(business['cost']) > 0: # è¿‡æ»¤æ‰ä»·æ ¼ä¸º0æˆ–æ— æ•ˆçš„æ•°æ®
                    costs.append(float(business['cost']))
            except (ValueError, TypeError): continue
        avg_rating = sum(ratings) / len(ratings) if ratings else 0
        avg_cost = sum(costs) / len(costs) if costs else 0
        return {'avg_rating': avg_rating, 'avg_cost': avg_cost}

    def get_rating_bonus(self, avg_rating):
        if avg_rating > 4.2: return (avg_rating - 4.2) * 25
        if avg_rating < 3.8 and avg_rating > 0: return (avg_rating - 3.8) * 20
        return 0

    # ã€æ”¹ã€‘é‡æ„æ¶ˆè´¹ç”»åƒåŠ åˆ†é€»è¾‘ï¼Œè´¯å½»â€œè¶Šä¾¿å®œè¶Šå¥½â€çš„åŸåˆ™
    def get_cost_bonus(self, avg_cost):
        """æ ¹æ®å‘¨è¾¹é¤é¥®äººå‡æ¶ˆè´¹è¯„ä¼°æ¶ˆè´¹ç”»åƒåŒ¹é…åº¦"""
        if avg_cost <= 0: return 0 # æ— æœ‰æ•ˆæ•°æ®
        if avg_cost <= 35: return 20  # æä½³ï¼Œæ¶ˆè´¹æ°´å¹³éå¸¸äº²æ°‘ï¼Œå®Œç¾åŒ¹é…ç›®æ ‡å®¢ç¾¤
        if avg_cost <= 50: return 10  # ä¸é”™ï¼Œæ¶ˆè´¹æ°´å¹³åˆç†ï¼ŒåŒ¹é…åº¦é«˜
        if avg_cost <= 80: return -5   # åé«˜ï¼Œå¯¹æ ¸å¿ƒå®¢ç¾¤æœ‰ä¸€å®šæ¶ˆè´¹å‹åŠ›
        return -15 # è¿‡é«˜ï¼ŒåŒºåŸŸæ¶ˆè´¹ä¸ç›®æ ‡å®¢ç¾¤ä¸¥é‡ä¸ç¬¦

    # ... append_to_summary_csv å’Œ get_rating_and_suggestion ä¸V10ç›¸åŒ ...
    def append_to_summary_csv(self, summary_data):
        timestamp = datetime.now().strftime("%Y%m%d")
        filename = f"analysis_summary_{timestamp}.csv"
        file_exists = os.path.isfile(filename)
        all_poi_names = list(MODEL_POI_CONFIG['positive'].keys()) + list(MODEL_POI_CONFIG['negative'].keys())
        fieldnames = ['åˆ†ææ—¶é—´', 'åœ°å€', 'åŠå¾„(ç±³)', 'æ€»åˆ†', 'è¯„çº§', 'æ ¸å¿ƒå®¢ç¾¤åˆ†', 'ååŒä¸šæ€åˆ†', 'åŸºç¡€è®¾æ–½åˆ†', 'ç«äº‰ç¯å¢ƒåˆ†', 'é£é™©é¡¹åˆ†', 'ä¸€å¥è¯å»ºè®®', 'ç»åº¦', 'çº¬åº¦', 'ç«äº‰å¯¹æ‰‹æ•°é‡', 'ä¸­å°å­¦æ•°é‡'] + \
                     [f"{name}_æ•°é‡" for name in all_poi_names]
        with open(filename, 'a', newline='', encoding='utf-8-sig') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames, extrasaction='ignore')
            if not file_exists: writer.writeheader()
            writer.writerow(summary_data)
        self.log(f"âœ… åˆ†æç»“æœå·²è¿½åŠ åˆ°æ±‡æ€»è¡¨: {filename}")

    def get_rating_and_suggestion(self, total_score, categorized_scores):
        policy_risk_count = categorized_scores.get("æ”¿ç­–é£é™©", {}).get("count", 0)
        if policy_risk_count > 0:
            return "F  é«˜å±", f"ã€ä¸€ç¥¨å¦å†³ã€‘å‘¨è¾¹{policy_risk_count}å®¶ä¸­å°å­¦ï¼Œå­˜åœ¨ä¸¥é‡æ”¿ç­–é£é™©ï¼Œç»å¯¹ä¸å»ºè®®ï¼"
        if total_score >= 180: return "S+ é¡¶çº§å•†åœˆ", "ç°è±¡çº§ä½ç½®ï¼Œå®¢æµå’Œæ¶ˆè´¹åŠ›é¡¶å°–ï¼Œæ˜¯å¸‚åœºæ ‡æ†ï¼Œå»ºè®®ä¸è®¡æˆæœ¬æ‹¿ä¸‹ã€‚"
        if 120 <= total_score < 180: return "A  æ ¸å¿ƒåŒºåŸŸ", "å®¢ç¾¤ç²¾å‡†ï¼Œé…å¥—å®Œå–„ï¼Œæ˜¯ç†æƒ³é€‰æ‹©ï¼ŒæˆåŠŸç‡æé«˜ã€‚"
        if 70 <= total_score < 120: return "B  æ½œåŠ›åŒºåŸŸ", "å…·å¤‡æ ¸å¿ƒä¼˜åŠ¿ï¼ˆå¦‚å¤§å­¦åŸæˆ–å¤§å‹ç¤¾åŒºï¼‰ï¼Œå¯é€šè¿‡è¿è¥å¼¥è¡¥çŸ­æ¿ã€‚"
        if 40 <= total_score < 70: return "C  è°¨æ…è€ƒè™‘", "å®¢æµæˆ–é…å¥—æœ‰æ˜æ˜¾çŸ­æ¿ï¼Œéœ€æ·±å…¥è°ƒç ”ç‰¹å®šå®¢ç¾¤ï¼Œé£é™©ä¸æœºé‡å¹¶å­˜ã€‚"
        return "D  é£é™©è¾ƒé«˜", "ç¼ºä¹æ ¸å¿ƒå®¢æµæ”¯æ’‘ï¼Œå•†ä¸šç¯å¢ƒä¸æˆç†Ÿï¼Œä¸å»ºè®®é€‰æ‹©ã€‚"

    def evaluate_location(self, address: str, radius: int):
        self.log("="*60); self.log(f"ğŸš€ å¼€å§‹æ–°ä»»åŠ¡: {address} (åŠå¾„: {radius}ç±³)")
        coords = self.get_coordinates(address)
        if not coords: self.log("âŒ ä»»åŠ¡ç»ˆæ­¢ã€‚"); return
        
        # ... å®šé‡åˆ†æéƒ¨åˆ†ä¸V10å®Œå…¨ç›¸åŒ ...
        categorized_scores = {
            "æ ¸å¿ƒå®¢ç¾¤": {"score": 0, "count": 0}, "ååŒä¸šæ€": {"score": 0, "count": 0},
            "åŸºç¡€è®¾æ–½": {"score": 0, "count": 0}, "ç›´æ¥ç«äº‰": {"score": 0, "count": 0},
            "æ”¿ç­–é£é™©": {"score": 0, "count": 0}, "é£é™©å®¢ç¾¤": {"score": 0, "count": 0}
        }
        summary_data = {'åœ°å€': address, 'åŠå¾„(ç±³)': radius, 'ç»åº¦': f"{coords[0]:.6f}", 'çº¬åº¦': f"{coords[1]:.6f}"}
        all_poi_configs = list(MODEL_POI_CONFIG['positive'].items()) + list(MODEL_POI_CONFIG['negative'].items())
        
        for i, (name, config) in enumerate(all_poi_configs):
            is_positive = name in MODEL_POI_CONFIG['positive']
            self.log(f"  [{i+1}/{len(all_poi_configs)}] æ­£åœ¨æŸ¥è¯¢({config['category']}): {name}...")
            raw_poi_list = self.search_nearby_poi_details_full(coords, radius, config.get('types'), config.get('keywords'), poi_name=name)
            if name == "ä¸­å°å­¦æ ¡":
                strict_radius = 200
                self.log(f"    -> å¯¹â€œä¸­å°å­¦æ ¡â€æ‰§è¡Œ {strict_radius}ç±³ ä¸¥æ ¼åŠå¾„ç­›æŸ¥...")
                raw_poi_list = [p for p in raw_poi_list if int(p.get('distance', 999)) <= strict_radius]
            cleaned_poi_list = self.clean_poi_list(raw_poi_list, config.get('types'))
            count = len(cleaned_poi_list)
            category = config['category']
            impact = 0
            if count > 0:
                if is_positive:
                    saturation = config.get('saturation')
                    effective_count = saturation * (1 - np.exp(-count / saturation)) if saturation else count
                    impact = effective_count * config['weight']
                    self.log(f"    -> å‘ç° {count} ä¸ª, æœ‰æ•ˆè®¡åˆ† {effective_count:.1f}, è´¡çŒ® +{impact:.1f}")
                else:
                    impact = count * config['weight']
                    self.log(f"    -> å‘ç° {count} ä¸ª, å½±å“ -{impact:.1f}")
            categorized_scores[category]['score'] += impact if is_positive else -impact
            categorized_scores[category]['count'] += count
            summary_data[f"{name}_æ•°é‡"] = count

        quantitative_score = (categorized_scores['æ ¸å¿ƒå®¢ç¾¤']['score'] + categorized_scores['ååŒä¸šæ€']['score'] + categorized_scores['åŸºç¡€è®¾æ–½']['score'])
        negative_score = (categorized_scores['ç›´æ¥ç«äº‰']['score'] + categorized_scores['æ”¿ç­–é£é™©']['score'] + categorized_scores['é£é™©å®¢ç¾¤']['score'])
        base_score = quantitative_score - negative_score

        # ã€æ”¹ã€‘è´¨åŒ–åˆ†ææ•°æ®æºæ›´ç²¾å‡†
        self.log("\n[+] æ­£åœ¨è¿›è¡Œå‘¨è¾¹ã€é¤é¥®æ¶ˆè´¹ã€‘ç”»åƒåˆ†æ...")
        # åªæŸ¥è¯¢â€œé¤é¥®æœåŠ¡â€å¤§ç±»(050000)ï¼Œç¡®ä¿æ•°æ®çº¯å‡€
        qualitative_pois = self.search_nearby_poi_details_full(coords, radius, poi_types="050000", poi_name="é¤é¥®æœåŠ¡")
        
        qualitative_results = self.analyze_poi_details(qualitative_pois)
        avg_rating, avg_cost = qualitative_results['avg_rating'], qualitative_results['avg_cost']
        quality_bonus = self.get_rating_bonus(avg_rating)
        profile_bonus = self.get_cost_bonus(avg_cost) # ä½¿ç”¨æ–°çš„è¯„åˆ†æ¨¡å‹
        total_score = base_score + quality_bonus + profile_bonus
        
        self.log(f"  - å‘¨è¾¹é¤é¥®å¹³å‡è¯„åˆ†: {avg_rating:.2f} -> è´¨é‡åŠ åˆ†: {quality_bonus:+.1f}")
        self.log(f"  - å‘¨è¾¹é¤é¥®äººå‡æ¶ˆè´¹: {avg_cost:.2f}å…ƒ -> ç”»åƒåŠ åˆ†: {profile_bonus:+.1f}")
        self.update_insight(avg_rating, avg_cost, quality_bonus, profile_bonus)

        # ... æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆä¸V10ç›¸åŒ ...
        self.log("\n" + "="*60); self.log("ğŸ“Š æœ€ç»ˆè¯„ä¼°æŠ¥å‘Š")
        self.log(f"  [+] æ ¸å¿ƒå®¢ç¾¤åŸºç¡€: {categorized_scores['æ ¸å¿ƒå®¢ç¾¤']['score']:.1f}åˆ† (æ¥è‡ªå¤§å­¦ã€ç¤¾åŒºã€å†™å­—æ¥¼ç­‰)")
        self.log(f"  [+] å•†ä¸šååŒæ•ˆåº”: {categorized_scores['ååŒä¸šæ€']['score']:.1f}åˆ† (æ¥è‡ªå•†åœºã€å¤œå¸‚ã€å½±é™¢ç­‰)")
        self.log(f"  [+] åŸºç¡€è®¾æ–½æ”¯æ’‘: {categorized_scores['åŸºç¡€è®¾æ–½']['score']:.1f}åˆ† (æ¥è‡ªåœ°é“ã€å…¬äº¤ç«™ç­‰)")
        self.log(f"  [-] ç«äº‰ç¯å¢ƒå‹åŠ›: -{categorized_scores['ç›´æ¥ç«äº‰']['score']:.1f}åˆ† ({categorized_scores['ç›´æ¥ç«äº‰']['count']}ä¸ªç›´æ¥ç«äº‰å¯¹æ‰‹)")
        self.log(f"  [-] æ½œåœ¨é£é™©å› ç´ : -{categorized_scores['æ”¿ç­–é£é™©']['score'] + categorized_scores['é£é™©å®¢ç¾¤']['score']:.1f}åˆ† (ä¸­å°å­¦: {categorized_scores['æ”¿ç­–é£é™©']['count']}ä¸ª, å·¥ä¸šåŒºç­‰: {categorized_scores['é£é™©å®¢ç¾¤']['count']}ä¸ª)")
        self.log("-" * 20)
        self.log(f"  åŸºç¡€å¾—åˆ† (å®¢ç¾¤+å•†ä¸š-ç«äº‰-é£é™©): {base_score:.2f}")
        self.log(f"  ç¯å¢ƒåŠ åˆ† (é¤é¥®è¯„çº§+æ¶ˆè´¹æ°´å¹³): {quality_bonus + profile_bonus:+.2f}")
        self.log(f"  æœ€ç»ˆæ€»åˆ†: {total_score:.2f}")
        grade, recommendation = self.get_rating_and_suggestion(total_score, categorized_scores)
        self.log(f"  è¯„çº§: {grade}")
        self.log(f"  å»ºè®®: {recommendation}")
        self.log("="*60 + "\n")

        summary_data.update({
            'åˆ†ææ—¶é—´': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'æ€»åˆ†': f"{total_score:.2f}", 'è¯„çº§': grade.split(" ")[0], 'ä¸€å¥è¯å»ºè®®': recommendation,
            'æ ¸å¿ƒå®¢ç¾¤åˆ†': f"{categorized_scores['æ ¸å¿ƒå®¢ç¾¤']['score']:.2f}", 'ååŒä¸šæ€åˆ†': f"{categorized_scores['ååŒä¸šæ€']['score']:.2f}",
            'åŸºç¡€è®¾æ–½åˆ†': f"{categorized_scores['åŸºç¡€è®¾æ–½']['score']:.2f}", 'ç«äº‰ç¯å¢ƒåˆ†': f"{-categorized_scores['ç›´æ¥ç«äº‰']['score']:.2f}",
            'é£é™©é¡¹åˆ†': f"{-categorized_scores['æ”¿ç­–é£é™©']['score'] - categorized_scores['é£é™©å®¢ç¾¤']['score']:.2f}",
            'ç«äº‰å¯¹æ‰‹æ•°é‡': categorized_scores['ç›´æ¥ç«äº‰']['count'], 'ä¸­å°å­¦æ•°é‡': categorized_scores['æ”¿ç­–é£é™©']['count']
        })
        self.append_to_summary_csv(summary_data)


# --- GUIç•Œé¢ (ä¸V10å®Œå…¨ç›¸åŒ, ä»…ä¿®æ”¹æ ‡é¢˜) ---
class App:
    def __init__(self, root):
        self.root = root
        self.root.title("ç½‘å§é€‰å€åˆ†æå™¨ v11.0 (æ¶ˆè´¹ç”»åƒä¼˜åŒ–ç‰ˆ)")
        self.root.geometry("800x650")

        main_frame = ttk.Frame(root, padding="10"); main_frame.pack(fill=tk.BOTH, expand=True)
        input_frame = ttk.LabelFrame(main_frame, text="å‚æ•°è®¾ç½®", padding="10"); input_frame.pack(fill=tk.X)
        ttk.Label(input_frame, text="åœ°å€è¾“å…¥ (ä¸€è¡Œä¸€ä¸ª):").pack(anchor='w')
        self.address_text = tk.Text(input_frame, height=5, width=60); self.address_text.pack(fill=tk.X, expand=True, pady=5)
        self.address_text.insert(tk.END, "æˆéƒ½ä¸œåŸæ—¶å…‰é“\næˆéƒ½å¡å¯†å°”ç”µç«\næˆéƒ½ä¿åˆ©Â·å¶è¯­")
        ttk.Label(input_frame, text="æœç´¢åŠå¾„ (ç±³):").pack(anchor='w', side=tk.LEFT, padx=(0, 5))
        self.radius_var = tk.StringVar(value="800")
        self.radius_entry = ttk.Entry(input_frame, textvariable=self.radius_var, width=10); self.radius_entry.pack(side=tk.LEFT)
        self.start_button = ttk.Button(input_frame, text="å¼€å§‹åˆ†æ", command=self.start_analysis_thread); self.start_button.pack(side=tk.RIGHT, padx=10)

        log_frame = ttk.LabelFrame(main_frame, text="åˆ†ææ—¥å¿—", padding="10"); log_frame.pack(fill=tk.BOTH, expand=True, pady=(10,0))
        self.log_text = scrolledtext.ScrolledText(log_frame, wrap=tk.WORD, state='disabled'); self.log_text.pack(fill=tk.BOTH, expand=True)
        qualitative_frame = ttk.LabelFrame(main_frame, text="é¤é¥®æ¶ˆè´¹ç”»åƒæ´å¯Ÿ", padding="10"); qualitative_frame.pack(fill=tk.X, pady=(5,0))
        self.qualitative_label = ttk.Label(qualitative_frame, text="ç­‰å¾…åˆ†æ...", font=("", 10))
        self.qualitative_label.pack(anchor='w')

    def log_to_gui(self, message):
        def _update():
            self.log_text.config(state='normal'); self.log_text.insert(tk.END, message + '\n')
            self.log_text.config(state='disabled'); self.log_text.see(tk.END)
        self.root.after(0, _update)

    def update_insight_display(self, avg_rating, avg_cost, quality_bonus, profile_bonus):
        def _update():
            text = (f"é¤é¥®è´¨é‡: å¹³å‡è¯„åˆ† {avg_rating:.2f} (åŠ åˆ†: {quality_bonus:+.1f}) | "
                    f"æ¶ˆè´¹æ°´å¹³: äººå‡æ¶ˆè´¹ {avg_cost:.2f}å…ƒ (ç”»åƒåŠ åˆ†: {profile_bonus:+.1f})")
            self.qualitative_label.config(text=text)
        self.root.after(0, _update)

    def start_analysis_thread(self):
        addresses = [addr.strip() for addr in self.address_text.get("1.0", tk.END).strip().split('\n') if addr.strip()]
        try: radius = int(self.radius_var.get()); assert 0 < radius <= 50000
        except (ValueError, AssertionError): self.log_to_gui("é”™è¯¯: åŠå¾„å¿…é¡»æ˜¯ 1 åˆ° 50000 ä¹‹é—´çš„æ•°å­—ã€‚"); return
        if not addresses: self.log_to_gui("é”™è¯¯: è¯·è‡³å°‘è¾“å…¥ä¸€ä¸ªåœ°å€ã€‚"); return
        self.start_button.config(state='disabled')
        self.update_insight_display(0, 0, 0, 0); self.qualitative_label.config(text="æ­£åœ¨åˆ†æ...")
        backup_dir = "raw_data_backup"
        if not os.path.exists(backup_dir): os.makedirs(backup_dir)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        csv_lock = threading.Lock()
        threading.Thread(target=self.run_analysis_with_backup, args=(addresses, radius, backup_dir, timestamp, csv_lock), daemon=True).start()

    def run_analysis_with_backup(self, addresses, radius, backup_dir, timestamp, lock):
        for i, address in enumerate(addresses):
            safe_address = "".join(x for x in address if x.isalnum())
            backup_filename = os.path.join(backup_dir, f"backup_{safe_address}_{timestamp}_{i+1}.csv")
            self.log_to_gui(f"ğŸ“ åŸå§‹æ•°æ®å°†å¤‡ä»½è‡³: {backup_filename}")
            with open(backup_filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
                fieldnames = ["timestamp", "request_type", "poi_name", "request_params", "response_status", "response_infocode", "response_count", "raw_json_response"]
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                with lock:
                    self.core = AnalysisCore(self.log_to_gui, self.update_insight_display, writer)
                self.core.evaluate_location(address, radius)
        self.log_to_gui("ğŸ‰ğŸ‰ğŸ‰ æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼ ğŸ‰ğŸ‰ğŸ‰")
        self.root.after(0, lambda: self.start_button.config(state='normal'))

if __name__ == "__main__":
    root = tk.Tk()
    app = App(root)
    root.mainloop()

# --- END OF FILE V11.py ---
